{
 "metadata": {
  "name": "",
  "signature": "sha256:c66df73b8528183bfafe2c041b82362e910b67c9dab12a4642c31fdf1a398b22"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Emotional motion development notes"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Objective: create a motion algorithm that will provide a unified method to move a central point in the whole robot and effectors in robot frame space. Contrasted to previous emotional motion method that moved each effector individually leading to motion conflicts e.g. lean back AND stand tall."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Need to understand effectors."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from naoqi import ALProxy\n",
      "import pprint\n",
      "\n",
      "NAO_IP = \"192.168.0.13\"\n",
      "\n",
      "motion = ALProxy(\"ALMotion\", NAO_IP, 9559)\n",
      "\n",
      "print motion.getSummary()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "---------------------- Model ---------------------------\n",
        "        BodyName   Stiffness     Command      Sensor\n",
        "         HeadYaw    0.000000   -0.024586   -0.024586\n",
        "       HeadPitch    0.000000    0.081260    0.081260\n",
        "  LShoulderPitch    0.000000    1.412772    1.412772\n",
        "   LShoulderRoll    0.000000    0.156426    0.156426\n",
        "       LElbowYaw    0.000000   -0.831470   -0.831470\n",
        "      LElbowRoll    0.000000   -1.069156   -1.069156\n",
        "       LWristYaw    0.000000    0.119610    0.119610\n",
        "    LHipYawPitch    0.000000   -0.248466   -0.248466\n",
        "        LHipRoll    0.000000   -0.079726   -0.079726\n",
        "       LHipPitch    0.000000   -0.699462   -0.699462\n",
        "      LKneePitch    0.000000    2.112546    2.112546\n",
        "     LAnklePitch    0.000000   -1.189442   -1.189442\n",
        "      LAnkleRoll    0.000000    0.070606    0.070606\n",
        "    RHipYawPitch    0.000000   -0.248466   -0.248466\n",
        "        RHipRoll    0.000000    0.078276    0.078276\n",
        "       RHipPitch    0.000000   -0.702614   -0.702614\n",
        "      RKneePitch    0.000000    2.112546    2.112546\n",
        "     RAnklePitch    0.000000   -1.186300   -1.186300\n",
        "      RAnkleRoll    0.000000   -0.075870   -0.075870\n",
        "  RShoulderPitch    0.000000    1.440468    1.440468\n",
        "   RShoulderRoll    0.000000   -0.162646   -0.162646\n",
        "       RElbowYaw    0.000000    0.809910    0.809910\n",
        "      RElbowRoll    0.000000    1.056968    1.056968\n",
        "       RWristYaw    0.000000   -0.101286   -0.101286\n",
        "           LHand    0.000000    0.010800    0.010800\n",
        "           RHand    0.000000    0.015600    0.015600\n",
        "---------------------- Tasks  --------------------------\n",
        "            Name          ID    BrokerID    Priority\n",
        "----------------- Motion Cycle Time --------------------\n",
        "              20 ms\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from naoqi import ALProxy\n",
      "import pprint\n",
      "\n",
      "NAO_IP = \"192.168.0.13\"\n",
      "\n",
      "motion = ALProxy(\"ALMotion\", NAO_IP, 9559)\n",
      "\n",
      "print motion.getBodyNames(\"Body\")\n",
      "print \"---------------\"\n",
      "print motion.getBodyNames(\"LArm\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['HeadYaw', 'HeadPitch', 'LShoulderPitch', 'LShoulderRoll', 'LElbowYaw', 'LElbowRoll', 'LWristYaw', 'LHand', 'LHipYawPitch', 'LHipRoll', 'LHipPitch', 'LKneePitch', 'LAnklePitch', 'LAnkleRoll', 'RHipYawPitch', 'RHipRoll', 'RHipPitch', 'RKneePitch', 'RAnklePitch', 'RAnkleRoll', 'RShoulderPitch', 'RShoulderRoll', 'RElbowYaw', 'RElbowRoll', 'RWristYaw', 'RHand']\n",
        "---------------\n",
        "['LShoulderPitch', 'LShoulderRoll', 'LElbowYaw', 'LElbowRoll', 'LWristYaw', 'LHand']\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "+ Cartesian example from Aldebaran [Cartesian control](http://doc.aldebaran.com/2-1/naoqi/motion/control-cartesian.html#control-cartesian)\n",
      "+ Changes: added dx variable for x moves, changed frame to frame relative to robot.\n",
      "+ First creates and loads arm movements and runs them in the background with post.\n",
      "+ Second creates and loads torso movements and runs them with a blocking call."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# -*- encoding: UTF-8 -*-\n",
      "\n",
      "'''Cartesian control: Multiple Effector Trajectories'''\n",
      "''' This example is only compatible with NAO '''\n",
      "\n",
      "import motion\n",
      "import almath\n",
      "from naoqi import ALProxy\n",
      "\n",
      "robotIP = \"192.168.0.13\"\n",
      "PORT=9559\n",
      "\n",
      "def main(robotIP, PORT):\n",
      "    ''' Simultaneously control three effectors:\n",
      "    the Torso, the Left Arm and the Right Arm\n",
      "    Warning: Needs a PoseInit before executing\n",
      "    '''\n",
      "\n",
      "    motionProxy  = ALProxy(\"ALMotion\", robotIP, PORT)\n",
      "    postureProxy = ALProxy(\"ALRobotPosture\", robotIP, PORT)\n",
      "    speechProxy = ALProxy(\"ALTextToSpeech\", robotIP, PORT)\n",
      "\n",
      "    # Wake up robot\n",
      "    motionProxy.wakeUp()\n",
      "\n",
      "    # Send robot to Stand Init\n",
      "    postureProxy.goToPosture(\"StandInit\", 0.5)\n",
      "\n",
      "    frame      = motion.FRAME_ROBOT\n",
      "    coef       = 0.5                   # motion speed\n",
      "    times      = [coef, 2.0*coef, 3.0*coef, 4.0*coef]\n",
      "    useSensorValues = False\n",
      "\n",
      "    # Relative movement between current and desired positions\n",
      "    dx         = +0.00                  # translation axis X (meters)\n",
      "    dy         = +0.0                 # translation axis Y (meters)\n",
      "    dz         = -0.0                 # translation axis Z (meters)\n",
      "    dwx        = +0.0*almath.TO_RAD   # rotation around axis X (radians)\n",
      "    dwy        = +0.0*almath.TO_RAD   # rotation around axis Y (radians)\n",
      "    dwz        = +8.0*almath.TO_RAD   # rotation around axis Z (radians)\n",
      "\n",
      "    # Motion of Torso with post process\n",
      "    effector   = \"Torso\"\n",
      "\n",
      "    path = []\n",
      "    initTf = almath.Transform(motionProxy.getTransform(effector, frame, useSensorValues))\n",
      "    # point 1\n",
      "    deltaTf  = almath.Transform(dx, -dy, dz)*almath.Transform().fromRotX(-dwx)*almath.Transform().fromRotY(dwy)*almath.Transform().fromRotZ(-dwz)\n",
      "    targetTf = initTf*deltaTf\n",
      "    path.append(list(targetTf.toVector()))\n",
      "\n",
      "    # point 2\n",
      "    path.append(list(initTf.toVector()))\n",
      "\n",
      "    # point 3\n",
      "    deltaTf  = almath.Transform(dx, dy, dz)*almath.Transform().fromRotX(dwx)\n",
      "    targetTf = initTf*deltaTf\n",
      "    path.append(list(targetTf.toVector()))\n",
      "\n",
      "    # point 4\n",
      "    path.append(list(initTf.toVector()))\n",
      "\n",
      "    axisMask   = almath.AXIS_MASK_ALL  # control all the effector axes\n",
      "    motionProxy.post.transformInterpolations(effector, frame, path,\n",
      "                                           axisMask, times)\n",
      "    # motionProxy.transformInterpolations(effector, frame, path,\n",
      "    #                                        axisMask, times)\n",
      "    speechProxy.post.say(\"Loaded first movement.\")\n",
      "\n",
      "    # Motion of Arms with block process\n",
      "    frame     = motion.FRAME_TORSO\n",
      "    axisMask  = almath.AXIS_MASK_VEL  # control just the position\n",
      "    times     = [1.0*coef, 2.0*coef]  # seconds\n",
      "\n",
      "    # Motion of Right Arm during the first half of the Torso motion\n",
      "    effector  = \"RArm\"\n",
      "\n",
      "    path = []\n",
      "    currentTf = motionProxy.getTransform(effector, frame, useSensorValues)\n",
      "    targetTf  = almath.Transform(currentTf)\n",
      "    targetTf.r2_c4 -= 0.04 # y\n",
      "    path.append(list(targetTf.toVector()))\n",
      "    path.append(currentTf)\n",
      "\n",
      "    motionProxy.transformInterpolations(effector, frame, path, axisMask, times)\n",
      "\n",
      "    # Motion of Left Arm during the last half of the Torso motion\n",
      "    effector   = \"LArm\"\n",
      "\n",
      "    path = []\n",
      "    currentTf = motionProxy.getTransform(effector, frame, useSensorValues)\n",
      "    targetTf  = almath.Transform(currentTf)\n",
      "    targetTf.r2_c4 += 0.04 # y\n",
      "    path.append(list(targetTf.toVector()))\n",
      "    path.append(currentTf)\n",
      "\n",
      "    motionProxy.transformInterpolations(effector, frame, path, axisMask, times)\n",
      "\n",
      "    # Go to rest position\n",
      "    motionProxy.rest()\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    main(robotIP, PORT)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Understanding transforms using ALMath [ALMath](http://doc.aldebaran.com/2-1/dev/python/examples/almath/index.html?highlight=almath) and an explanation of the rotation matrices [ALMath C++ Overview](http://doc.aldebaran.com/2-1/ref/libalmath/a00001.html)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# -*- encoding: UTF-8 -*-\n",
      "\n",
      "''' Example showing how to use almath with python and send the results to\n",
      "    the robot by using a proxy to ALMotion '''\n",
      "\n",
      "import argparse\n",
      "import time\n",
      "\n",
      "from naoqi import ALProxy\n",
      "\n",
      "import almath\n",
      "\n",
      "robotIP = \"192.168.0.13\"\n",
      "PORT = 9559\n",
      "\n",
      "def main(robotIP, PORT):\n",
      "\n",
      "    # Create a proxy to ALMotion.\n",
      "    try:\n",
      "        motionProxy = ALProxy(\"ALMotion\", robotIP, PORT)\n",
      "    except Exception,e:\n",
      "        print \"Could not create proxy to ALMotion\"\n",
      "        print \"Error was: \",e\n",
      "\n",
      "    # Create a proxy to ALRobotPosture.\n",
      "    try:\n",
      "        postureProxy = ALProxy(\"ALRobotPosture\", robotIP, PORT)\n",
      "    except Exception,e:\n",
      "        print \"Could not create proxy to ALRobotPosture\"\n",
      "        print \"Error was: \",e\n",
      "\n",
      "    # WakeUp\n",
      "    motionProxy.wakeUp()\n",
      "\n",
      "    # Stand up.\n",
      "    postureProxy.goToPosture(\"StandInit\", 0.3)\n",
      "\n",
      "    chainName = \"RArm\"\n",
      "    frame = 2 # FRAME_WORLD {FRAME_TORSO = 0, FRAME_WORLD = 1, FRAME_ROBOT = 2}.\n",
      "    useSensors = True\n",
      "\n",
      "    ##############################################\n",
      "    # Retrieve a transform matrix using ALMotion #\n",
      "    ##############################################\n",
      "\n",
      "    # Retrieve current transform from ALMotion.\n",
      "    # Convert it to a transform matrix for ALMath.\n",
      "    origTransform = almath.Transform(\n",
      "        motionProxy.getTransform(chainName, frame, useSensors))\n",
      "\n",
      "    # Visualize the transform using overriden print from ALMath\n",
      "    print \"Original transform\"\n",
      "    print origTransform\n",
      "\n",
      "    ##########################################################\n",
      "    # Use almath to do some computations on transform matrix #\n",
      "    ##########################################################\n",
      "\n",
      "    # Compute a transform corresponding to the desired move\n",
      "    # (here, move the chain for 5cm along the Z axis and the X axis).\n",
      "    moveTransform = almath.Transform.fromPosition(0.05, 0.0, 0.05)\n",
      "\n",
      "    # Compute the corresponding target transform.\n",
      "    targetTransform = moveTransform * origTransform\n",
      "\n",
      "    # Visualize it.\n",
      "    print \"Target transform\"\n",
      "    print targetTransform\n",
      "\n",
      "    ##############################################\n",
      "    # Send a transform to the robot via ALMotion #\n",
      "    ##############################################\n",
      "\n",
      "    # Convert it to a tuple.\n",
      "    targetTransformList = list(targetTransform.toVector())\n",
      "\n",
      "    # Send the target transform to NAO through ALMotion.\n",
      "    fractionOfMaxSpeed = 0.5\n",
      "    axisMask = almath.AXIS_MASK_VEL # Translation X, Y, Z\n",
      "    motionProxy.setTransforms(\n",
      "        chainName,\n",
      "        frame,\n",
      "        targetTransformList,\n",
      "        fractionOfMaxSpeed,\n",
      "        axisMask)\n",
      "\n",
      "    time.sleep(2.0)\n",
      "    motionProxy.rest()\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    main(robotIP, PORT)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Original transform\n",
        "[[0.823939, 0.536812, 0.18154, 0.113418]\n",
        " [0.0293247, 0.279538, -0.959687, -0.126002]\n",
        " [-0.565919, 0.796047, 0.21458, 0.254484]]\n",
        "Target transform\n",
        "[[0.823939, 0.536812, 0.18154, 0.163418]\n",
        " [0.0293247, 0.279538, -0.959687, -0.126002]\n",
        " [-0.565919, 0.796047, 0.21458, 0.304484]]\n"
       ]
      }
     ],
     "prompt_number": 17
    }
   ],
   "metadata": {}
  }
 ]
}